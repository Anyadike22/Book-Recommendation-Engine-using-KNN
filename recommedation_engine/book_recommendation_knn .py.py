# -*- coding: utf-8 -*-
"""fcc_book_recommendation_knn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/freeCodeCamp/boilerplate-book-recommendation-engine/blob/master/fcc_book_recommendation_knn.ipynb
"""

# import libraries (you may add additional imports but you may not have to)
import numpy as np
import pandas as pd
from scipy.sparse import csr_matrix
from sklearn.neighbors import NearestNeighbors
model_knn=NearestNeighbors(metric='cosine',algorithm='brute')
model_knn.fit(matrix)
import matplotlib.pyplot as plt

# get data files
!wget https://cdn.freecodecamp.org/project-data/books/book-crossings.zip

!unzip book-crossings.zip

books_filename = 'BX-Books.csv'
ratings_filename = 'BX-Book-Ratings.csv'

# import csv data into dataframes
df_books = pd.read_csv(
    books_filename,
    encoding = "ISO-8859-1",
    sep=";",
    header=0,
    names=['isbn', 'title', 'author'],
    usecols=['isbn', 'title', 'author'],
    dtype={'isbn': 'str', 'title': 'str', 'author': 'str'})

df_ratings = pd.read_csv(
    ratings_filename,
    encoding = "ISO-8859-1",
    sep=";",
    header=0,
    names=['user', 'isbn', 'rating'],
    usecols=['user', 'isbn', 'rating'],
    dtype={'user': 'int32', 'isbn': 'str', 'rating': 'float32'})

# Checking the features of the dataframe
df_books.info()

df_ratings.info()

df_books.head()

df_ratings.head()

# Pre-process the dataframe to create a pivot table based on the condition: remove from the dataset users with less than 200 ratings and books with less than 100 ratings.
df = df_ratings

# Filter out users with less than 200 ratings and books with less than 100 ratings
user_counts = df['user'].value_counts()
isbn_counts = df['isbn'].value_counts()

df = df[df['user'].isin(user_counts[user_counts >= 200].index)]
df = df[df['isbn'].isin(isbn_counts[isbn_counts >= 100].index)]

# Merge with df_books on 'isbn'
df = pd.merge(left=df, right=df_books, on="isbn")

# Drop duplicate entries based on 'title' and 'user'
df = df.drop_duplicates(["title", "user"])

# Pivot the DataFrame
pivoted_df = df.pivot(index='title', columns='user', values='rating').fillna(0)

matrix_shape = piv.values.shape
print(matrix_shape)

piv.head()

piv

# function to return recommended books - this will be tested
def get_recommends(book=""):
    # Reshape the selected book's ratings into a 2D array
    x = piv.loc[book].values.reshape(1, -1)

    # Compute nearest neighbors
    distances, indices = model_knn.kneighbors(x, n_neighbors=6)

    # Initialize recommended books list
    recommended_books = []

    # Iterate over distances and indices to find recommended books
    for distance, index in zip(distances[0], indices[0]):
        # Check if the distance is not zero (excluding the selected book itself)
        if distance != 0:
            # Get the recommended book and its distance
            recommended_book = piv.index[index]
            recommended_books.append([recommended_book, distance])

    # Reverse the order of recommended books and return the result
    return [book, recommended_books[::-1]]

books = get_recommends("Where the Heart Is (Oprah's Book Club (Paperback))")
print(books)

def test_book_recommendation():
  test_pass = True
  recommends = get_recommends("Where the Heart Is (Oprah's Book Club (Paperback))")
  if recommends[0] != "Where the Heart Is (Oprah's Book Club (Paperback))":
    test_pass = False
  recommended_books = ["I'll Be Seeing You", 'The Weight of Water', 'The Surgeon', 'I Know This Much Is True']
  recommended_books_dist = [0.8, 0.77, 0.77, 0.77]
  for i in range(2):
    if recommends[1][i][0] not in recommended_books:
      test_pass = False
    if abs(recommends[1][i][1] - recommended_books_dist[i]) >= 0.05:
      test_pass = False
  if test_pass:
    print("You passed the challenge! ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰")
  else:
    print("You haven't passed yet. Keep trying!")

test_book_recommendation()